# Environment variables for the Video-to-Shorts Pipeline

# LLM Provider Configuration
# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11444/llm/
OLLAMA_BEARER_TOKEN=olLtzB4RaUYurrFgz4BVEJeygrCd4XCVxO

# OpenAI Configuration (required when using OpenAI provider)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o
OPENAI_BASE_URL=https://api.openai.com/v1

# Model configurations
YOLO_MODEL_PATH=yolov8n.pt
WHISPER_MODEL_SIZE=base
WHISPER_DEVICE=cuda

# Processing settings
BATCH_SIZE=32
MAX_WORKERS=4
TEMP_DIR=temp
CACHE_DIR=cache

# Video output settings
OUTPUT_FORMAT=mp4
OUTPUT_QUALITY=high
TARGET_DURATION_MIN=15
TARGET_DURATION_MAX=60

# Smart zoom settings
FACE_CONFIDENCE_THRESHOLD=0.7
PERSON_CONFIDENCE_THRESHOLD=0.8
OBJECT_CONFIDENCE_THRESHOLD=0.6
TRACKING_PERSISTENCE_FRAMES=10

# GPU settings
CUDA_VISIBLE_DEVICES=0
TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6"
